from pathlib import Path
import clip
import torch
from PIL import Image
import json

device = "cuda" if torch.cuda.is_available() else "cpu"


# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ ‚Äî –±—É–¥–µ –≤–∏–∫–æ–Ω–∞–Ω–æ –ª–∏—à–µ –æ–¥–∏–Ω —Ä–∞–∑
_model = None
_preprocess = None

def load_clip_model():
    global _model, _preprocess
    if _model is None or _preprocess is None:
        _model, _preprocess = clip.load("ViT-B/32", device=device)

def load_local_image(path):
    return Image.open(path).convert("RGB")

def load_weapons_db(json_path):
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def collect_image_folders(root_path):
    folders = []
    for path in Path(root_path).rglob('*'):
        if path.is_dir():
            images = list(path.glob('*.jpg')) + list(path.glob('*.jpeg')) + list(path.glob('*.png'))
            if images:
                folders.append(path)
    return folders

def recognize_weapon(test_image_path, reference_folder, db_path):
    load_clip_model()

    weapons_db = load_weapons_db(db_path)
    test_image = _preprocess(load_local_image(test_image_path)).unsqueeze(0).to(device)

    best_match = None
    highest_similarity = -1
    match_info = None

    for model_path in collect_image_folders(reference_folder):
        model_name = model_path.name
        similarities = []

        for image_path in model_path.glob("*"):
            if not image_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                continue
            try:
                ref_image = _preprocess(load_local_image(str(image_path))).unsqueeze(0).to(device)
                with torch.no_grad():
                    test_features = _model.encode_image(test_image)
                    ref_features = _model.encode_image(ref_image)
                similarity = torch.nn.functional.cosine_similarity(test_features, ref_features).item()
                similarities.append(similarity)
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑ —Ñ–∞–π–ª–æ–º {image_path}: {e}")

        if similarities:
            avg_similarity = sum(similarities) / len(similarities)
            if avg_similarity > highest_similarity:
                highest_similarity = avg_similarity
                best_match = model_name
                match_info = next((item for item in weapons_db if item["label"] == model_name), None)

    if highest_similarity < 0.7:
        return (
            f"‚ö†Ô∏è –ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –Ω–∞–¥—Ç–æ –Ω–∏–∑—å–∫–∞ (—Å—Ö–æ–∂—ñ—Å—Ç—å: {highest_similarity:.2f}).\n"
            f"–û–±‚Äô—î–∫—Ç –Ω–µ —Å—Ö–æ–∂–∏–π –Ω–∞ –≤—ñ–¥–æ–º—ñ –∑—Ä–∞–∑–∫–∏ –∑–±—Ä–æ—ó –∞–±–æ –±–æ—î–ø—Ä–∏–ø–∞—Å—ñ–≤.\n"
            f"–Ø–∫—â–æ –º–∞—î—Ç–µ —Å—É–º–Ω—ñ–≤–∏ ‚Äî –Ω–µ –Ω–∞–±–ª–∏–∂–∞–π—Ç–µ—Å—å —ñ –∑–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –î–°–ù–° –∞–±–æ –ø–æ–ª—ñ—Ü—ñ—ó."
        )

    output = ""

    if match_info:
        output += f"‚úÖ –ú–æ–¥–µ–ª—å: {match_info['name_ua']}\n"
        output += f"üìå –¢–∏–ø: {match_info['type']} ({match_info['category']})\n"
        output += f"üè≥Ô∏è –ö—Ä–∞—ó–Ω–∞: {match_info['country']}\n"
        output += f"üî´ –ö–∞–ª—ñ–±—Ä: {match_info['caliber']}\n"
        output += f"üìè –°—Ö–æ–∂—ñ—Å—Ç—å: {highest_similarity:.4f}\n"

        if match_info["category"] in ["–≥—Ä–∞–Ω–∞—Ç–∏", "–º—ñ–Ω–∏"] and highest_similarity > 0.8:
            output += "‚ö†Ô∏è –£–≤–∞–≥–∞! –û–±'—î–∫—Ç –º–æ–∂–µ –±—É—Ç–∏ –≤–∏–±—É—Ö–æ–Ω–µ–±–µ–∑–ø–µ—á–Ω–∏–º. –ù–µ —Ç–æ—Ä–∫–∞–π—Ç–µ—Å—å!"
    elif best_match:
        output += f"‚úÖ –ù–∞–π–±—ñ–ª—å—à —Å—Ö–æ–∂–∞ –º–æ–¥–µ–ª—å: {best_match}\nüìè –°—Ö–æ–∂—ñ—Å—Ç—å: {highest_similarity:.4f}"
    else:
        output = "‚ùå –ñ–æ–¥–Ω–æ–≥–æ –∑–±—ñ–≥—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."

    return output
